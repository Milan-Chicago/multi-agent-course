{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNuwDCgsV1yblP1Cb15nTXi",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hamzafarooq/multi-agent-course/blob/main/Module_4/knowledge_graph_neo4j_with_evals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### **Welcome to the RAG vs KG Evaluation Notebook**\n",
    "\n",
    "In this notebook, we implement **Retrieval-Augmented Generation (RAG)** and **Knowledge Graph (KG)** pipelines **from scratch \u2014 with no LangChain, LlamaIndex, or external orchestration frameworks**.\n",
    "Our goal is to show exactly what's possible when you understand and control every component end-to-end.\n",
    "\n",
    "You'll see how to build retrieval, graph reasoning, and evaluation logic using **pure Python**, giving you maximum transparency and customizability.\n",
    "\n",
    "This notebook serves as a foundation for benchmarking, extending, and adapting both approaches to real enterprise use cases.\n"
   ],
   "metadata": {
    "id": "ly_QfX8FbfOY"
   }
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## \ud83c\udf93 **Want to Master Multi-Agent Systems?**\n\nThis notebook is part of the **Advanced LLM Multi-Agent Architecture Course** where you'll learn:\n\n- \u2705 How to build production-ready RAG systems\n- \u2705 Knowledge Graph integration with LLMs\n- \u2705 Multi-agent orchestration patterns\n- \u2705 Evaluation frameworks and best practices\n- \u2705 Real-world case studies and implementations\n\n**[\ud83d\udc49 Join the Course Now](https://maven.com/boring-bot/advanced-llm?promoCode=200OFF)** - Use code **`200OFF`** for $200 off!\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)\n"
   ],
   "metadata": {
    "id": "smEJkJ8UYgJp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install neo4j openai python-dotenv"
   ],
   "metadata": {
    "id": "0QNgTXqRXkTc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv('/content/Neo4j-324820c6-Created-2025-12-05.txt', override=True)"
   ],
   "metadata": {
    "id": "eJl8lxlPXq6v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "# If using Colab, you can store your API key in the secrets manager and access it like this:\n",
    "from google.colab import userdata\n",
    "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# # Otherwise, load from environment variables:\n",
    "# OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found. Please set it as an environment variable or in Colab secrets.\")"
   ],
   "metadata": {
    "id": "s35gcXnJXt9Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# **RAG vs Knowledge Graph: A Comprehensive Comparison Framework**\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "This implementation provides a production-ready framework for evaluating two powerful question-answering approaches: **Retrieval-Augmented Generation (RAG)** and **Knowledge Graph (KG) queries via Text-to-Cypher**.\n",
    "\n",
    "Built on **Neo4j Aura** and **OpenAI GPT-4o-minio-mini**, this system allows objective measurement of which approach works best for different types of questions.\n",
    "\n",
    "---\n",
    "\n",
    "## **What This Does**\n",
    "\n",
    "This codebase implements **three distinct query methods** and compares them head-to-head:\n",
    "\n",
    "### **1. RAG (Retrieval-Augmented Generation)**\n",
    "\n",
    "* Uses semantic search (embeddings) or keyword matching to find relevant documents\n",
    "* Passes retrieved context to an LLM for answer generation\n",
    "* **Best for:** natural language understanding, semantic queries, summarization\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Knowledge Graph with Text-to-Cypher**\n",
    "\n",
    "* Converts natural language questions into Cypher using GPT-4o-minio-mini\n",
    "* Executes structured queries directly on Neo4j\n",
    "* Returns exact, verifiable data\n",
    "* **Best for:** precise counts, relationship queries, aggregations, filtering\n",
    "\n",
    "---\n",
    "\n",
    "### **3. LLM Judge Evaluation**\n",
    "\n",
    "* Uses GPT-4o-minio-mini as an impartial evaluator\n",
    "* Scores each method on accuracy, completeness, precision, and verifiability\n",
    "* Produces detailed reasoning and recommendations\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Features**\n",
    "\n",
    "* \u2705 **No Hardcoded Queries** \u2014 Cypher is generated dynamically\n",
    "* \u2705 **Objective Evaluation** \u2014 unbiased LLM-based scoring\n",
    "* \u2705 **Production Ready** \u2014 graceful error handling, retry logic, logging\n",
    "* \u2705 **Flexible Data Loading** \u2014 CSV support (URL or local)\n",
    "* \u2705 **Vector Search Optional** \u2014 embedding-based semantic RAG\n",
    "* \u2705 **Batch Evaluation** \u2014 evaluate many questions together\n",
    "* \u2705 **Interactive Mode** \u2014 ask questions in real time\n",
    "\n",
    "---\n",
    "\n",
    "## **Architecture**\n",
    "\n",
    "```\n",
    "CopyQuestion\n",
    "    \u2193\n",
    "    \u251c\u2500\u2500 [RAG Path] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 Answer A (Interpretive)\n",
    "    \u2502\n",
    "    \u251c\u2500\u2500 [Knowledge Graph Path] \u2192 Answer B (Exact)\n",
    "    \u2502\n",
    "    \u2514\u2500\u2500 [LLM Judge] \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 Winner + Analysis\n",
    "```\n",
    "\n",
    "### **RAG Path**\n",
    "\n",
    "1. Convert question to embedding or keywords\n",
    "2. Retrieve relevant articles from Neo4j\n",
    "3. Pass context to GPT-4o-minio-mini for answer generation\n",
    "\n",
    "### **Knowledge Graph Path**\n",
    "\n",
    "1. Convert question to Cypher using GPT-4o-minio-mini\n",
    "2. Execute structured query on Neo4j\n",
    "3. Format results + natural-language explanation\n",
    "\n",
    "### **Judge Path**\n",
    "\n",
    "* Compares both answers\n",
    "* Scores accuracy, precision, completeness\n",
    "* Determines winner with detailed reasoning\n",
    "\n",
    "---\n",
    "\n",
    "## **Use Cases**\n",
    "\n",
    "### **When Knowledge Graph Wins**\n",
    "\n",
    "* *\u201cWho are the collaborators of Emily Chen?\u201d*\n",
    "* *\u201cHow many articles has each researcher published?\u201d*\n",
    "* *\u201cWhich researchers work on AI Ethics?\u201d*\n",
    "* *\u201cFind all papers published in 2024.\u201d*\n",
    "\n",
    "### **When RAG Wins**\n",
    "\n",
    "* *\u201cWhat are the main challenges in AI safety?\u201d*\n",
    "* *\u201cExplain innovations in transformer architectures.\u201d*\n",
    "* *\u201cSummarize ethical concerns in AI research.\u201d*\n",
    "\n",
    "### **When Both Are Useful**\n",
    "\n",
    "* *\u201cWhat topics does Emily Chen research?\u201d*\n",
    "* *\u201cCompare research focus of two researchers.\u201d*\n",
    "\n",
    "---\n",
    "\n",
    "## **Data Schema**\n",
    "\n",
    "The system works with research paper data including:\n",
    "\n",
    "* **Articles:** title, abstract, publication date\n",
    "* **Researchers:** names + co-authorship\n",
    "* **Topics:** research areas\n",
    "* **Relationships:**\n",
    "\n",
    "  * `PUBLISHED` (Researcher \u2192 Article)\n",
    "  * `IN_TOPIC` (Article \u2192 Topic)\n",
    "\n",
    "---\n",
    "\n",
    "## **Quick Start**\n",
    "\n",
    "```python\n",
    "# Single question comparison\n",
    "quick_ask_with_judge(\"Who are the collaborators of Emily Chen?\")\n",
    "\n",
    "# Batch evaluation\n",
    "questions = [\n",
    "    \"How many articles has each researcher published?\",\n",
    "    \"What are the ethical concerns in AI?\",\n",
    "    \"Which researchers work on Model Optimization?\"\n",
    "]\n",
    "batch_judge_questions(questions)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Expected Results**\n",
    "\n",
    "You will get:\n",
    "\n",
    "* Winner declaration for each question\n",
    "* Confidence level (high/medium/low)\n",
    "* Metrics: accuracy, completeness, precision\n",
    "* LLM reasoning explaining the decision\n",
    "* Recommendations for the best approach per question type\n",
    "\n",
    "---\n",
    "\n",
    "## **Why This Matters**\n",
    "\n",
    "Most implementations choose *either* RAG or Knowledge Graphs.\n",
    "\n",
    "This framework shows **when to use which**, backed by objective LLM evaluations\u2014ideal for:\n",
    "\n",
    "* Building hybrid QA systems leveraging both methods\n",
    "* Understanding semantic vs. structured query trade-offs\n",
    "* Making informed architectural decisions\n",
    "* Demonstrating the value of Knowledge Graphs vs pure LLM approaches\n"
   ],
   "metadata": {
    "id": "L5Rq_9q5Zr3q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "import openai\n",
    "from typing import List, Dict, Any\n",
    "import time\n",
    "import json\n",
    "\n",
    "class Neo4jGraphRAG:\n",
    "    def __init__(self):\n",
    "        self.uri = os.getenv(\"NEO4J_URI\")\n",
    "        self.username = os.getenv(\"NEO4J_USERNAME\")\n",
    "        self.password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "        self.database = os.getenv(\"NEO4J_DATABASE\", \"neo4j\")\n",
    "\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            self.uri,\n",
    "            auth=(self.username, self.password)\n",
    "        )\n",
    "\n",
    "        openai.api_key = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def execute_query(self, query: str, parameters: Dict = None) -> List[Dict]:\n",
    "        \"\"\"Execute a Cypher query and return results\"\"\"\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            result = session.run(query, parameters or {})\n",
    "            return [record.data() for record in result]\n",
    "\n",
    "    def load_data(self, csv_url: str):\n",
    "        \"\"\"Load data from CSV into Neo4j\"\"\"\n",
    "        q_load = f\"\"\"\n",
    "        LOAD CSV WITH HEADERS\n",
    "        FROM '{csv_url}'\n",
    "        AS row\n",
    "        FIELDTERMINATOR ';'\n",
    "        MERGE (a:Article {{title:row.Title}})\n",
    "        SET a.abstract = row.Abstract,\n",
    "            a.publication_date = date(row.Publication_Date)\n",
    "        WITH a, row\n",
    "        FOREACH (researcher in split(row.Authors, ',') |\n",
    "            MERGE (p:Researcher {{name:trim(researcher)}})\n",
    "            MERGE (p)-[:PUBLISHED]->(a))\n",
    "        WITH a, row\n",
    "        FOREACH (topic in [row.Topic] |\n",
    "            MERGE (t:Topic {{name:trim(topic)}})\n",
    "            MERGE (a)-[:IN_TOPIC]->(t))\n",
    "        \"\"\"\n",
    "        return self.execute_query(q_load)\n",
    "\n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate embeddings using OpenAI\"\"\"\n",
    "        response = openai.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=text\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    def create_embeddings_for_articles(self):\n",
    "        \"\"\"Create and store embeddings for all articles\"\"\"\n",
    "        articles = self.execute_query(\"\"\"\n",
    "            MATCH (a:Article)\n",
    "            RETURN id(a) as id, a.title as title, a.abstract as abstract\n",
    "        \"\"\")\n",
    "\n",
    "        print(f\"Creating embeddings for {len(articles)} articles...\")\n",
    "        for i, article in enumerate(articles, 1):\n",
    "            text = f\"{article['title']} {article['abstract']}\"\n",
    "            embedding = self.get_embedding(text)\n",
    "\n",
    "            self.execute_query(\"\"\"\n",
    "                MATCH (a:Article)\n",
    "                WHERE id(a) = $id\n",
    "                SET a.embedding = $embedding\n",
    "            \"\"\", {\n",
    "                \"id\": article['id'],\n",
    "                \"embedding\": embedding\n",
    "            })\n",
    "\n",
    "            if i % 10 == 0:\n",
    "                print(f\"  Progress: {i}/{len(articles)}\")\n",
    "\n",
    "        print(f\"\u2705 Created embeddings for all {len(articles)} articles\")\n",
    "\n",
    "    def retrieve_context(self, question: str, limit: int = 5) -> str:\n",
    "        \"\"\"Retrieve relevant context from the graph based on the question.\"\"\"\n",
    "        keywords = question.lower().split()\n",
    "\n",
    "        cypher_query = \"\"\"\n",
    "        MATCH (a:Article)\n",
    "        WHERE ANY(keyword IN $keywords WHERE\n",
    "            toLower(a.title) CONTAINS keyword OR\n",
    "            toLower(a.abstract) CONTAINS keyword)\n",
    "        OPTIONAL MATCH (a)-[:IN_TOPIC]->(t:Topic)\n",
    "        OPTIONAL MATCH (r:Researcher)-[:PUBLISHED]->(a)\n",
    "        WITH a,\n",
    "             collect(DISTINCT t.name) as topics,\n",
    "             collect(DISTINCT r.name) as authors\n",
    "        RETURN a.title as title,\n",
    "               a.abstract as abstract,\n",
    "               a.publication_date as date,\n",
    "               topics,\n",
    "               authors\n",
    "        ORDER BY size(authors) DESC\n",
    "        LIMIT $limit\n",
    "        \"\"\"\n",
    "\n",
    "        results = self.execute_query(cypher_query, {\n",
    "            \"keywords\": keywords,\n",
    "            \"limit\": limit\n",
    "        })\n",
    "\n",
    "        context_parts = []\n",
    "        for i, record in enumerate(results, 1):\n",
    "            context = f\"\"\"\n",
    "Article {i}: {record['title']}\n",
    "Authors: {', '.join(record['authors']) if record['authors'] else 'N/A'}\n",
    "Topics: {', '.join(record['topics']) if record['topics'] else 'N/A'}\n",
    "Abstract: {record['abstract']}\n",
    "Date: {record['date']}\n",
    "---\"\"\"\n",
    "            context_parts.append(context)\n",
    "\n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    def retrieve_with_vector_search(self, question: str, limit: int = 5) -> str:\n",
    "        \"\"\"Retrieve using vector similarity\"\"\"\n",
    "        embedding = self.get_embedding(question)\n",
    "\n",
    "        cypher_query = \"\"\"\n",
    "        MATCH (a:Article)\n",
    "        WHERE a.embedding IS NOT NULL\n",
    "        WITH a,\n",
    "             gds.similarity.cosine(a.embedding, $query_embedding) AS similarity\n",
    "        ORDER BY similarity DESC\n",
    "        LIMIT $limit\n",
    "        OPTIONAL MATCH (a)-[:IN_TOPIC]->(t:Topic)\n",
    "        OPTIONAL MATCH (r:Researcher)-[:PUBLISHED]->(a)\n",
    "        WITH a, similarity,\n",
    "             collect(DISTINCT t.name) as topics,\n",
    "             collect(DISTINCT r.name) as authors\n",
    "        RETURN a.title as title,\n",
    "               a.abstract as abstract,\n",
    "               topics,\n",
    "               authors,\n",
    "               similarity\n",
    "        \"\"\"\n",
    "\n",
    "        results = self.execute_query(cypher_query, {\n",
    "            \"query_embedding\": embedding,\n",
    "            \"limit\": limit\n",
    "        })\n",
    "\n",
    "        context_parts = []\n",
    "        for i, record in enumerate(results, 1):\n",
    "            context = f\"\"\"\n",
    "Article {i} (Similarity: {record['similarity']:.3f}):\n",
    "Title: {record['title']}\n",
    "Authors: {', '.join(record['authors'])}\n",
    "Topics: {', '.join(record['topics'])}\n",
    "Abstract: {record['abstract']}\n",
    "---\"\"\"\n",
    "            context_parts.append(context)\n",
    "\n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    def generate_answer(self, question: str, context: str) -> str:\n",
    "        \"\"\"Generate answer using LLM with retrieved context\"\"\"\n",
    "        prompt = f\"\"\"You are a helpful assistant that answers questions based on the provided context from a knowledge graph.\n",
    "\n",
    "Context from Knowledge Graph:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please provide a comprehensive answer based on the context above. If the context doesn't contain enough information to answer the question, say so.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def query(self, question: str, use_vector_search: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Main RAG query method.\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        if use_vector_search:\n",
    "            context = self.retrieve_with_vector_search(question)\n",
    "        else:\n",
    "            context = self.retrieve_context(question)\n",
    "\n",
    "        if not context:\n",
    "            return {\n",
    "                \"answer\": \"I couldn't find any relevant information in the knowledge graph.\",\n",
    "                \"context\": \"\",\n",
    "                \"sources\": [],\n",
    "                \"time\": time.time() - start_time\n",
    "            }\n",
    "\n",
    "        answer = self.generate_answer(question, context)\n",
    "\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"context\": context,\n",
    "            \"sources\": self.extract_sources(context),\n",
    "            \"time\": time.time() - start_time\n",
    "        }\n",
    "\n",
    "    def extract_sources(self, context: str) -> List[str]:\n",
    "        \"\"\"Extract article titles from context as sources\"\"\"\n",
    "        sources = []\n",
    "        for line in context.split('\\n'):\n",
    "            if line.startswith('Article') and ':' in line:\n",
    "                title = line.split(':', 1)[1].strip()\n",
    "                sources.append(title)\n",
    "        return sources\n",
    "\n",
    "    # ============================================\n",
    "    # TEXT-TO-CYPHER FUNCTIONALITY\n",
    "    # ============================================\n",
    "\n",
    "    def get_graph_schema(self) -> str:\n",
    "        \"\"\"Get the current graph schema\"\"\"\n",
    "        sample_query = \"\"\"\n",
    "        MATCH (r:Researcher)-[:PUBLISHED]->(a:Article)-[:IN_TOPIC]->(t:Topic)\n",
    "        RETURN r.name as researcher, a.title as article, t.name as topic\n",
    "        LIMIT 3\n",
    "        \"\"\"\n",
    "\n",
    "        samples = self.execute_query(sample_query)\n",
    "\n",
    "        schema = f\"\"\"\n",
    "Graph Database Schema:\n",
    "=====================\n",
    "\n",
    "Node Types:\n",
    "-----------\n",
    "1. Researcher\n",
    "   Properties: name (string)\n",
    "   Example: \"Emily Chen\", \"Dr. Sarah Williams\"\n",
    "\n",
    "2. Article\n",
    "   Properties: title (string), abstract (string), publication_date (date)\n",
    "   Example: \"AI in Healthcare\", \"Machine Learning Applications\"\n",
    "\n",
    "3. Topic\n",
    "   Properties: name (string)\n",
    "   Example: \"Artificial Intelligence\", \"Climate Change\"\n",
    "\n",
    "Relationships:\n",
    "--------------\n",
    "1. (Researcher)-[:PUBLISHED]->(Article)\n",
    "   - A researcher published an article\n",
    "\n",
    "2. (Article)-[:IN_TOPIC]->(Topic)\n",
    "   - An article belongs to a topic\n",
    "\n",
    "Important Notes:\n",
    "----------------\n",
    "- Multiple researchers can publish the SAME article (co-authorship)\n",
    "- An article can have multiple topics\n",
    "- Use MATCH patterns to find relationships\n",
    "- Use WHERE clauses for filtering\n",
    "- Use toLower() for case-insensitive matching\n",
    "- Property access: node.property (e.g., r.name, a.title)\n",
    "\n",
    "Sample Data:\n",
    "------------\n",
    "\"\"\"\n",
    "        for sample in samples:\n",
    "            schema += f\"\\n\u2022 {sample['researcher']} -> {sample['article'][:50]}... -> {sample['topic']}\"\n",
    "\n",
    "        return schema\n",
    "\n",
    "    def text_to_cypher(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Convert natural language question to Cypher query using LLM\"\"\"\n",
    "        schema = self.get_graph_schema()\n",
    "\n",
    "        prompt = f\"\"\"{schema}\n",
    "\n",
    "Task: Convert the following natural language question into a valid Neo4j Cypher query.\n",
    "\n",
    "Rules:\n",
    "1. Return ONLY the Cypher query, no explanations\n",
    "2. Use proper Neo4j syntax\n",
    "3. Use MATCH for finding patterns\n",
    "4. Use WHERE for filtering\n",
    "5. Use RETURN to specify what to return\n",
    "6. Use toLower() for case-insensitive text matching\n",
    "7. Limit results to 20 unless asked otherwise\n",
    "8. For \"collaborators\", find researchers who published the SAME article\n",
    "9. For counting, use count() function\n",
    "10. For finding by name, use WHERE node.name = \"exact name\" or CONTAINS for partial match\n",
    "\n",
    "Common Query Patterns:\n",
    "- Find collaborators: MATCH (r1:Researcher)-[:PUBLISHED]->(a:Article)<-[:PUBLISHED]-(r2:Researcher)\n",
    "- Count articles: MATCH (r:Researcher)-[:PUBLISHED]->(a) RETURN r.name, count(a)\n",
    "- Find by topic: MATCH (a:Article)-[:IN_TOPIC]->(t:Topic) WHERE toLower(t.name) CONTAINS 'keyword'\n",
    "- Find researcher's work: MATCH (r:Researcher {{name: \"Name\"}})-[:PUBLISHED]->(a) RETURN a.title\n",
    "\n",
    "Question: \"{question}\"\n",
    "\n",
    "Cypher Query:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a Neo4j Cypher query expert. Generate only valid, executable Cypher queries. Be precise with syntax.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0.1,\n",
    "                max_tokens=300\n",
    "            )\n",
    "\n",
    "            cypher = response.choices[0].message.content.strip()\n",
    "            cypher = cypher.replace(\"```cypher\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"cypher\": cypher,\n",
    "                \"error\": None\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"cypher\": None,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def execute_text_to_cypher(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate Cypher from text and execute it\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        cypher_result = self.text_to_cypher(question)\n",
    "\n",
    "        if not cypher_result['success']:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to generate Cypher: {cypher_result['error']}\",\n",
    "                \"time\": time.time() - start_time\n",
    "            }\n",
    "\n",
    "        cypher = cypher_result['cypher']\n",
    "\n",
    "        try:\n",
    "            results = self.execute_query(cypher)\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"cypher\": cypher,\n",
    "                \"results\": results,\n",
    "                \"result_count\": len(results),\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"error\": None\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"cypher\": cypher,\n",
    "                \"results\": [],\n",
    "                \"result_count\": 0,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"error\": f\"Cypher execution error: {str(e)}\"\n",
    "            }\n",
    "\n",
    "    def format_kg_results(self, results: List[Dict]) -> str:\n",
    "        \"\"\"Format KG results into readable text\"\"\"\n",
    "        if not results:\n",
    "            return \"No results found.\"\n",
    "\n",
    "        formatted = []\n",
    "        for i, row in enumerate(results[:20], 1):\n",
    "            row_text = f\"Result {i}:\"\n",
    "            for key, value in row.items():\n",
    "                if isinstance(value, list):\n",
    "                    value = \", \".join(str(v) for v in value[:5])\n",
    "                row_text += f\"\\n  \u2022 {key}: {value}\"\n",
    "            formatted.append(row_text)\n",
    "\n",
    "        return \"\\n\\n\".join(formatted)\n",
    "\n",
    "    def kg_query_with_explanation(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute KG query and generate natural language explanation\"\"\"\n",
    "        start_time = time.time()\n",
    "\n",
    "        kg_result = self.execute_text_to_cypher(question)\n",
    "\n",
    "        if not kg_result['success']:\n",
    "            return {\n",
    "                \"method\": \"Knowledge Graph (Text-to-Cypher)\",\n",
    "                \"success\": False,\n",
    "                \"error\": kg_result['error'],\n",
    "                \"answer\": f\"Failed to query knowledge graph: {kg_result['error']}\",\n",
    "                \"time\": time.time() - start_time\n",
    "            }\n",
    "\n",
    "        formatted_results = self.format_kg_results(kg_result['results'])\n",
    "\n",
    "        explanation_prompt = f\"\"\"You are explaining database query results to a user.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Cypher Query Used:\n",
    "{kg_result['cypher']}\n",
    "\n",
    "Query Results:\n",
    "{formatted_results}\n",
    "\n",
    "Provide a clear, natural language answer based on these EXACT results. Be specific with numbers and names from the data. If there are no results, say so clearly.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that explains database query results clearly and accurately.\"},\n",
    "                    {\"role\": \"user\", \"content\": explanation_prompt}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=500\n",
    "            )\n",
    "\n",
    "            answer = response.choices[0].message.content\n",
    "\n",
    "        except Exception as e:\n",
    "            answer = f\"Found {kg_result['result_count']} results, but failed to generate explanation: {str(e)}\"\n",
    "\n",
    "        return {\n",
    "            \"method\": \"Knowledge Graph (Text-to-Cypher)\",\n",
    "            \"success\": True,\n",
    "            \"cypher\": kg_result['cypher'],\n",
    "            \"results\": kg_result['results'],\n",
    "            \"result_count\": kg_result['result_count'],\n",
    "            \"formatted_results\": formatted_results,\n",
    "            \"answer\": answer,\n",
    "            \"time\": time.time() - start_time\n",
    "        }\n",
    "\n",
    "    # ============================================\n",
    "    # LLM JUDGE COMPARISON\n",
    "    # ============================================\n",
    "\n",
    "    def compare_with_judge(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Use LLM to judge which method (RAG vs KG) gave a better answer\"\"\"\n",
    "        print(\"\\n\" + \"\u2696\ufe0f \" * 40)\n",
    "        print(\"LLM JUDGE: Comparing RAG vs Knowledge Graph\")\n",
    "        print(\"\u2696\ufe0f \" * 40)\n",
    "        print(f\"\\nQuestion: {question}\\n\")\n",
    "\n",
    "        # Get both results\n",
    "        print(\"\ud83d\udd04 Getting RAG answer...\")\n",
    "        rag_result = self.query(question, use_vector_search=False)\n",
    "\n",
    "        print(\"\ud83d\udd04 Getting Knowledge Graph answer...\")\n",
    "        kg_result = self.kg_query_with_explanation(question)\n",
    "\n",
    "        # Display both answers\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"\ud83d\udcda RAG ANSWER:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(rag_result['answer'])\n",
    "        print(f\"\u23f1\ufe0f  Time: {rag_result['time']:.2f}s\")\n",
    "        print(f\"\ud83d\udcc4 Sources: {len(rag_result['sources'])} documents\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"\ud83d\udd0d KNOWLEDGE GRAPH ANSWER:\")\n",
    "        print(\"-\" * 80)\n",
    "        if kg_result['success']:\n",
    "            print(f\"Cypher: {kg_result['cypher']}\")\n",
    "            print(f\"\\n{kg_result['answer']}\")\n",
    "            print(f\"\u23f1\ufe0f  Time: {kg_result['time']:.2f}s\")\n",
    "            print(f\"\ud83d\udcca Results: {kg_result['result_count']} exact matches\")\n",
    "        else:\n",
    "            print(f\"\u274c Failed: {kg_result['error']}\")\n",
    "\n",
    "        # If KG failed, RAG wins by default\n",
    "        if not kg_result['success']:\n",
    "            print(\"\\n\" + \"\ud83c\udfc6\" * 40)\n",
    "            print(\"WINNER: RAG (Knowledge Graph query failed)\")\n",
    "            print(\"\ud83c\udfc6\" * 40)\n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"winner\": \"RAG\",\n",
    "                \"reason\": \"Knowledge Graph query failed\",\n",
    "                \"rag_result\": rag_result,\n",
    "                \"kg_result\": kg_result,\n",
    "                \"judgment\": None\n",
    "            }\n",
    "\n",
    "        # Ask LLM to judge\n",
    "        print(\"\\n\ud83e\udd14 Asking LLM judge to evaluate...\")\n",
    "\n",
    "        judgment_prompt = f\"\"\"You are an expert judge evaluating two AI systems answering the same question.\n",
    "\n",
    "Question: \"{question}\"\n",
    "\n",
    "SYSTEM A (RAG - Retrieval-Augmented Generation):\n",
    "Answer: {rag_result['answer']}\n",
    "Method: Retrieved {len(rag_result['sources'])} relevant documents and generated answer using LLM\n",
    "Time: {rag_result['time']:.2f}s\n",
    "\n",
    "SYSTEM B (Knowledge Graph with Text-to-Cypher):\n",
    "Cypher Query: {kg_result['cypher']}\n",
    "Answer: {kg_result['answer']}\n",
    "Method: Generated structured database query and retrieved {kg_result['result_count']} exact results\n",
    "Time: {kg_result['time']:.2f}s\n",
    "Raw Results: {kg_result['formatted_results'][:500]}...\n",
    "\n",
    "Evaluation Criteria:\n",
    "1. **Accuracy**: Which answer is more factually correct?\n",
    "2. **Completeness**: Which answer provides more complete information?\n",
    "3. **Precision**: Which answer is more specific and exact?\n",
    "4. **Verifiability**: Which answer can be verified/proven?\n",
    "5. **Usefulness**: Which answer better serves the user's intent?\n",
    "\n",
    "Provide your evaluation in the following JSON format:\n",
    "{{\n",
    "    \"winner\": \"A\" or \"B\" or \"TIE\",\n",
    "    \"confidence\": \"high\" or \"medium\" or \"low\",\n",
    "    \"accuracy_score_a\": 1-10,\n",
    "    \"accuracy_score_b\": 1-10,\n",
    "    \"completeness_score_a\": 1-10,\n",
    "    \"completeness_score_b\": 1-10,\n",
    "    \"precision_score_a\": 1-10,\n",
    "    \"precision_score_b\": 1-10,\n",
    "    \"reasoning\": \"Detailed explanation of your judgment\",\n",
    "    \"strengths_a\": [\"strength 1\", \"strength 2\"],\n",
    "    \"strengths_b\": [\"strength 1\", \"strength 2\"],\n",
    "    \"weaknesses_a\": [\"weakness 1\", \"weakness 2\"],\n",
    "    \"weaknesses_b\": [\"weakness 1\", \"weakness 2\"],\n",
    "    \"recommendation\": \"When to use each method for this type of question\"\n",
    "}}\n",
    "\n",
    "Be objective and thorough in your analysis.\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert AI judge evaluating different question-answering systems. Be objective, thorough, and fair in your evaluations.\"},\n",
    "                    {\"role\": \"user\", \"content\": judgment_prompt}\n",
    "                ],\n",
    "                temperature=0.3,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "\n",
    "            judgment_text = response.choices[0].message.content.strip()\n",
    "\n",
    "            # Try to parse JSON\n",
    "            try:\n",
    "                if \"```json\" in judgment_text:\n",
    "                    judgment_text = judgment_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "                elif \"```\" in judgment_text:\n",
    "                    judgment_text = judgment_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "\n",
    "                judgment = json.loads(judgment_text)\n",
    "            except json.JSONDecodeError:\n",
    "                judgment = {\"raw_text\": judgment_text}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error getting LLM judgment: {e}\")\n",
    "            judgment = {\"error\": str(e)}\n",
    "\n",
    "        # Display judgment\n",
    "        print(\"\\n\" + \"\ud83c\udfc6\" * 40)\n",
    "        print(\"LLM JUDGE VERDICT\")\n",
    "        print(\"\ud83c\udfc6\" * 40)\n",
    "\n",
    "        if \"error\" in judgment:\n",
    "            print(f\"\u274c Error: {judgment['error']}\")\n",
    "        elif \"raw_text\" in judgment:\n",
    "            print(judgment['raw_text'])\n",
    "        else:\n",
    "            winner_map = {\"A\": \"RAG\", \"B\": \"Knowledge Graph\", \"TIE\": \"TIE\"}\n",
    "            winner = winner_map.get(judgment.get('winner', 'UNKNOWN'), 'UNKNOWN')\n",
    "\n",
    "            print(f\"\\n\ud83c\udfaf WINNER: {winner}\")\n",
    "            print(f\"\ud83d\udcca Confidence: {judgment.get('confidence', 'unknown').upper()}\")\n",
    "\n",
    "            print(f\"\\n\ud83d\udcc8 Scores:\")\n",
    "            print(f\"  RAG:\")\n",
    "            print(f\"    \u2022 Accuracy: {judgment.get('accuracy_score_a', 'N/A')}/10\")\n",
    "            print(f\"    \u2022 Completeness: {judgment.get('completeness_score_a', 'N/A')}/10\")\n",
    "            print(f\"    \u2022 Precision: {judgment.get('precision_score_a', 'N/A')}/10\")\n",
    "\n",
    "            print(f\"  Knowledge Graph:\")\n",
    "            print(f\"    \u2022 Accuracy: {judgment.get('accuracy_score_b', 'N/A')}/10\")\n",
    "            print(f\"    \u2022 Completeness: {judgment.get('completeness_score_b', 'N/A')}/10\")\n",
    "            print(f\"    \u2022 Precision: {judgment.get('precision_score_b', 'N/A')}/10\")\n",
    "\n",
    "            print(f\"\\n\ud83d\udcad Reasoning:\")\n",
    "            print(f\"  {judgment.get('reasoning', 'No reasoning provided')}\")\n",
    "\n",
    "            if judgment.get('strengths_a'):\n",
    "                print(f\"\\n\u2705 RAG Strengths:\")\n",
    "                for strength in judgment['strengths_a']:\n",
    "                    print(f\"  \u2022 {strength}\")\n",
    "\n",
    "            if judgment.get('strengths_b'):\n",
    "                print(f\"\\n\u2705 Knowledge Graph Strengths:\")\n",
    "                for strength in judgment['strengths_b']:\n",
    "                    print(f\"  \u2022 {strength}\")\n",
    "\n",
    "            if judgment.get('weaknesses_a'):\n",
    "                print(f\"\\n\u26a0\ufe0f  RAG Weaknesses:\")\n",
    "                for weakness in judgment['weaknesses_a']:\n",
    "                    print(f\"  \u2022 {weakness}\")\n",
    "\n",
    "            if judgment.get('weaknesses_b'):\n",
    "                print(f\"\\n\u26a0\ufe0f  Knowledge Graph Weaknesses:\")\n",
    "                for weakness in judgment['weaknesses_b']:\n",
    "                    print(f\"  \u2022 {weakness}\")\n",
    "\n",
    "            if judgment.get('recommendation'):\n",
    "                print(f\"\\n\ud83d\udca1 Recommendation:\")\n",
    "                print(f\"  {judgment['recommendation']}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"winner\": judgment.get('winner'),\n",
    "            \"confidence\": judgment.get('confidence'),\n",
    "            \"judgment\": judgment,\n",
    "            \"rag_result\": rag_result,\n",
    "            \"kg_result\": kg_result\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# STANDALONE HELPER FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def quick_ask_with_judge(question: str):\n",
    "    \"\"\"Quick function to ask a question and get LLM judgment\"\"\"\n",
    "    rag = Neo4jGraphRAG()\n",
    "\n",
    "    # Check if data exists\n",
    "    count = rag.execute_query(\"MATCH (n) RETURN count(n) as count\")\n",
    "    if count[0]['count'] == 0:\n",
    "        print(\"\ud83d\udce5 Loading data first...\")\n",
    "        rag.load_data('https://raw.githubusercontent.com/dcarpintero/generative-ai-101/main/dataset/synthetic_articles.csv')\n",
    "\n",
    "        # Check if embeddings exist\n",
    "        emb_count = rag.execute_query(\"MATCH (a:Article) WHERE a.embedding IS NOT NULL RETURN count(a) as count\")\n",
    "        if emb_count[0]['count'] == 0:\n",
    "            print(\"\ud83d\udd22 Creating embeddings...\")\n",
    "            rag.create_embeddings_for_articles()\n",
    "\n",
    "    result = rag.compare_with_judge(question)\n",
    "    rag.close()\n",
    "    return result\n",
    "\n",
    "\n",
    "def batch_judge_questions(questions: List[str]):\n",
    "    \"\"\"Judge multiple questions and show aggregate statistics\"\"\"\n",
    "    print(\"\\n\" + \"\ud83c\udfaf\" * 40)\n",
    "    print(\"BATCH LLM JUDGMENT - Multiple Questions\")\n",
    "    print(\"\ud83c\udfaf\" * 40)\n",
    "\n",
    "    rag = Neo4jGraphRAG()\n",
    "\n",
    "    # Check/load data\n",
    "    count = rag.execute_query(\"MATCH (n) RETURN count(n) as count\")\n",
    "    if count[0]['count'] == 0:\n",
    "        print(\"\ud83d\udce5 Loading data...\")\n",
    "        rag.load_data('https://raw.githubusercontent.com/dcarpintero/generative-ai-101/main/dataset/synthetic_articles.csv')\n",
    "        print(\"\ud83d\udd22 Creating embeddings...\")\n",
    "        rag.create_embeddings_for_articles()\n",
    "\n",
    "    results = []\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Question {i}/{len(questions)}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        result = rag.compare_with_judge(question)\n",
    "        results.append(result)\n",
    "\n",
    "        if i < len(questions):\n",
    "            time.sleep(1)\n",
    "\n",
    "    # Aggregate statistics\n",
    "    print(\"\\n\" + \"\ud83d\udcca\" * 40)\n",
    "    print(\"AGGREGATE STATISTICS\")\n",
    "    print(\"\ud83d\udcca\" * 40)\n",
    "\n",
    "    rag_wins = sum(1 for r in results if r.get('winner') == 'A')\n",
    "    kg_wins = sum(1 for r in results if r.get('winner') == 'B')\n",
    "    ties = sum(1 for r in results if r.get('winner') == 'TIE')\n",
    "\n",
    "    print(f\"\\n\ud83c\udfc6 Overall Results:\")\n",
    "    print(f\"  \u2022 RAG Wins: {rag_wins}/{len(questions)} ({rag_wins/len(questions)*100:.1f}%)\")\n",
    "    print(f\"  \u2022 Knowledge Graph Wins: {kg_wins}/{len(questions)} ({kg_wins/len(questions)*100:.1f}%)\")\n",
    "    print(f\"  \u2022 Ties: {ties}/{len(questions)} ({ties/len(questions)*100:.1f}%)\")\n",
    "\n",
    "    # Average scores\n",
    "    rag_accuracy = [r['judgment'].get('accuracy_score_a', 0) for r in results if 'judgment' in r and r['judgment'] and isinstance(r['judgment'].get('accuracy_score_a'), (int, float))]\n",
    "    kg_accuracy = [r['judgment'].get('accuracy_score_b', 0) for r in results if 'judgment' in r and r['judgment'] and isinstance(r['judgment'].get('accuracy_score_b'), (int, float))]\n",
    "\n",
    "    if rag_accuracy and kg_accuracy:\n",
    "        print(f\"\\n\ud83d\udcc8 Average Accuracy Scores:\")\n",
    "        print(f\"  \u2022 RAG: {sum(rag_accuracy)/len(rag_accuracy):.1f}/10\")\n",
    "        print(f\"  \u2022 Knowledge Graph: {sum(kg_accuracy)/len(kg_accuracy):.1f}/10\")\n",
    "\n",
    "    # Question type analysis\n",
    "    print(f\"\\n\ud83d\udd0d Question Type Analysis:\")\n",
    "    for i, (question, result) in enumerate(zip(questions, results), 1):\n",
    "        winner_name = {\"A\": \"RAG\", \"B\": \"KG\", \"TIE\": \"TIE\"}.get(result.get('winner'), '?')\n",
    "        print(f\"  {i}. {question[:60]}...\")\n",
    "        print(f\"     Winner: {winner_name}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    rag.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# USAGE EXAMPLES\n",
    "# ============================================\n",
    "\n"
   ],
   "metadata": {
    "id": "3V2RLeKWP2lf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Example 1: Single question with judgment\n",
    "print(\"Example 1: Single Question\")\n",
    "quick_ask_with_judge(\"Who are the collaborators of Emily Chen?\")\n",
    "\n",
    "# Example 2: Batch judgment of multiple questions\n",
    "# print(\"\\n\\nExample 2: Batch Questions\")\n",
    "# test_questions = [\n",
    "#     \"Who are the collaborators of Emily Chen?\",\n",
    "#     \"How many articles has each researcher published?\",\n",
    "#     \"What are the most popular research topics?\",\n",
    "#     \"Which researchers work on AI?\",\n",
    "# ]\n",
    "# batch_judge_questions(test_questions)"
   ],
   "metadata": {
    "id": "VpSNC1TYYkc0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Batch mode with multiple questions"
   ],
   "metadata": {
    "id": "_1Mlgqd4Y3VX"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# **Evaluation Question Sets (Overview Only)**\n",
    "\n",
    "This evaluation framework organizes questions into eight categories based on which method\u2014**RAG** or **Knowledge Graph (KG)**\u2014is expected to perform better. Each category targets different reasoning patterns, allowing you to benchmark strengths, weaknesses, and ideal use-cases.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Relationship Queries**\n",
    "\n",
    "**Expected Winner: Knowledge Graph**\n",
    "These questions test the system\u2019s ability to traverse structured relationships between entities.\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* Who are the collaborators of Emily Chen?\n",
    "* Which researchers have co-authored papers with David Johnson?\n",
    "* Find all researchers who have worked with Sarah Lee.\n",
    "* Which authors have published together on AI Ethics?\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Counting & Aggregation**\n",
    "\n",
    "**Expected Winner: Knowledge Graph**\n",
    "These require exact counts, grouping, and structured aggregations.\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* How many articles has each researcher published?\n",
    "* Which researcher has published the most papers?\n",
    "* How many papers are there on each topic?\n",
    "* What is the total number of publications in 2023?\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Filtering & Specific Queries**\n",
    "\n",
    "**Expected Winner: Knowledge Graph**\n",
    "KG excels when filtering based on explicit attributes or relationships.\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* Show me all articles published by Emily Chen.\n",
    "* What papers did Lisa Wang publish in 2024?\n",
    "* Which papers were published after January 2024?\n",
    "* Show me articles on AI Ethics published in 2023.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Topic-Based Queries**\n",
    "\n",
    "**Expected Winner: Mixed (RAG + KG)**\n",
    "These evaluate both semantic understanding (RAG) and structured topic associations (KG).\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* What topics does Emily Chen research?\n",
    "* Which researchers work on AI Ethics?\n",
    "* What are the main research areas in the dataset?\n",
    "* What subtopics are covered under Foundations of Language Models?\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Semantic / Content Queries**\n",
    "\n",
    "**Expected Winner: RAG**\n",
    "RAG is stronger for interpretive, narrative, and content-based reasoning.\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* What are the main challenges in AI safety?\n",
    "* Explain the innovations in transformer architectures.\n",
    "* What approaches are proposed for privacy in AI?\n",
    "* Summarize the research on language model optimization.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Complex Multi-Hop Queries**\n",
    "\n",
    "**Expected Winner: Knowledge Graph**\n",
    "These require multi-step reasoning across connected entities.\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* Which researchers work on the same topics as Emily Chen?\n",
    "* Find researchers who collaborate with colleagues of David Johnson.\n",
    "* What topics connect Michael Brown and Sarah Lee?\n",
    "* Which researchers published in both 2023 and 2024?\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Temporal Queries**\n",
    "\n",
    "**Expected Winner: Knowledge Graph**\n",
    "KG handles exact dates, ranges, and chronological patterns.\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* What research was published in the last quarter of 2023?\n",
    "* Which topics were most popular in 2024?\n",
    "* What was the first paper published on AI Ethics?\n",
    "* Compare publication activity between 2023 and 2024.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Comparison Queries**\n",
    "\n",
    "**Expected Winner: Mixed**\n",
    "These require both factual comparison (KG) and interpretive analysis (RAG).\n",
    "\n",
    "Example questions:\n",
    "\n",
    "* Compare the research focus of Emily Chen vs Michael Brown.\n",
    "* Which topic has more researchers: AI Ethics or Language Models?\n",
    "* Who is more prolific: David Johnson or Sarah Lee?\n",
    "* Compare collaboration patterns across research areas.\n",
    "\n",
    "---\n",
    "\n",
    "# **Additional Evaluation Sets**\n",
    "\n",
    "## **Quick Evaluation Set (10 Questions)**\n",
    "\n",
    "A fast benchmark across all categories:\n",
    "\n",
    "* Relationship, counting, filtering, topic, semantic, complex, temporal, and comparison questions.\n",
    "\n",
    "## **Medium Evaluation Set (20 Questions)**\n",
    "\n",
    "Balanced sampling across:\n",
    "\n",
    "* Relationship\n",
    "* Counting\n",
    "* Topic\n",
    "* Semantic\n",
    "* Complex\n",
    "* Temporal\n",
    "\n",
    "## **Strength/Weakness Diagnostic Set**\n",
    "\n",
    "Highlights scenarios where each method performs best\u2014or struggles:\n",
    "\n",
    "* KG strengths: collaboration networks, exact counts, date-range queries\n",
    "* RAG strengths: summaries, innovations, ethical concerns\n",
    "* Edge cases: citation impact, subjective comparisons, predictive reasoning\n",
    "\n"
   ],
   "metadata": {
    "id": "Yteh9LRJayyj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# **\ud83d\udcc8 Decision Flowchart: Should You Use KG or RAG?**\n",
    "\n",
    "```\n",
    "                         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                         \u2502     Start with Query     \u2502\n",
    "                         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                      \u2502\n",
    "                                      \u25bc\n",
    "                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                     \u2502 Does the question require EXACT     \u2502\n",
    "                     \u2502 data, numbers, or factual recall?   \u2502\n",
    "                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                       \u2502 Yes\n",
    "                                       \u25bc\n",
    "                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                          \u2502     Use KNOWLEDGE GRAPH     \u2502\n",
    "                          \u2502  (Structured, deterministic) \u2502\n",
    "                          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                         \u2502\n",
    "                                         \u25bc\n",
    "                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                   \u2502 Examples:                                     \u2502\n",
    "                   \u2502  \u2022 Who collaborated with X?                   \u2502\n",
    "                   \u2502  \u2022 How many papers in 2024?                   \u2502\n",
    "                   \u2502  \u2022 List all articles by Emily Chen           \u2502\n",
    "                   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "\n",
    "                                      \u25b2\n",
    "                                      \u2502 No\n",
    "                                      \u2502\n",
    "                                      \u25bc\n",
    "                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                 \u2502 Does the question require SEMANTIC reasoning,  \u2502\n",
    "                 \u2502 interpretation, summarization, or explanation? \u2502\n",
    "                 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                           \u2502 Yes\n",
    "                                           \u25bc\n",
    "                             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                             \u2502         Use RAG           \u2502\n",
    "                             \u2502 (Unstructured reasoning)  \u2502\n",
    "                             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                          \u2502\n",
    "                                          \u25bc\n",
    "               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "               \u2502 Examples:                                       \u2502\n",
    "               \u2502  \u2022 What are the challenges in AI Safety?        \u2502\n",
    "               \u2502  \u2022 Summarize research on transformer models     \u2502\n",
    "               \u2502  \u2022 What are ethical concerns in AI research?    \u2502\n",
    "               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "\n",
    "                                      \u25b2\n",
    "                                      \u2502 No\n",
    "                                      \u2502\n",
    "                                      \u25bc\n",
    "          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "          \u2502 Is the question multi-hop, relational, or graph-based? \u2502\n",
    "          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                    \u2502 Yes\n",
    "                                    \u25bc\n",
    "                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                       \u2502     Use KNOWLEDGE GRAPH   \u2502\n",
    "                       \u2502   (Multi-hop traversal)   \u2502\n",
    "                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "\n",
    "                                      \u25b2\n",
    "                                      \u2502 No\n",
    "                                      \u2502\n",
    "                                      \u25bc\n",
    "       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "       \u2502 Is the question subjective, comparative, or mixed-mode?\u2502\n",
    "       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                                 \u2502 Yes\n",
    "                                 \u25bc\n",
    "        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "        \u2502 Use BOTH \u2192 Hybrid KG + RAG (Best for comparisons)      \u2502\n",
    "        \u2502 Example: \u201cCompare Emily Chen vs Michael Brown\u201d         \u2502\n",
    "        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "\n",
    "\n",
    "                                     \u25b2\n",
    "                                     \u2502 No\n",
    "                                     \u2502\n",
    "                                     \u25bc\n",
    "                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                       \u2502  Default: Try both KG and RAG   \u2502\n",
    "                       \u2502  (Let evaluator choose winner)  \u2502\n",
    "                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "QZ2uIiStbHGQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# EVALUATION QUESTION SETS\n",
    "# ============================================\n",
    "\n",
    "# SET 1: RELATIONSHIP QUERIES (KG should excel)\n",
    "relationship_questions = [\n",
    "    \"Who are the collaborators of Emily Chen?\",\n",
    "    \"Which researchers have co-authored papers with David Johnson?\",\n",
    "    \"Find all researchers who have worked with Sarah Lee\",\n",
    "    \"Who has Michael Brown collaborated with?\",\n",
    "    \"Which authors have published together on AI Ethics?\",\n",
    "]\n",
    "\n",
    "# SET 2: COUNTING & AGGREGATION (KG should dominate)\n",
    "counting_questions = [\n",
    "    \"How many articles has each researcher published?\",\n",
    "    \"Which researcher has published the most papers?\",\n",
    "    \"How many papers are there on each topic?\",\n",
    "    \"Count the number of articles in AI Ethics\",\n",
    "    \"Which topic has the most publications?\",\n",
    "    \"How many researchers work on Foundations of Language Models?\",\n",
    "    \"What is the total number of publications in 2023?\",\n",
    "]\n",
    "\n",
    "# SET 3: FILTERING & SPECIFIC QUERIES (KG should win)\n",
    "filtering_questions = [\n",
    "    \"Show me all articles published by Emily Chen\",\n",
    "    \"What papers did Lisa Wang publish in 2024?\",\n",
    "    \"Find articles about Model Optimization\",\n",
    "    \"Which papers were published after January 2024?\",\n",
    "    \"List all researchers working on Safety subtopic\",\n",
    "    \"Show me articles on AI Ethics published in 2023\",\n",
    "]\n",
    "\n",
    "# SET 4: TOPIC-BASED QUERIES (Mixed - both methods useful)\n",
    "topic_questions = [\n",
    "    \"What topics does Emily Chen research?\",\n",
    "    \"Which researchers work on AI Ethics?\",\n",
    "    \"What are the main research areas in the dataset?\",\n",
    "    \"Who works on Model Architectures?\",\n",
    "    \"Find all researchers interested in Social Impact\",\n",
    "    \"What subtopics are covered under Foundations of Language Models?\",\n",
    "]\n",
    "\n",
    "# SET 5: SEMANTIC/CONTENT QUERIES (RAG should excel)\n",
    "semantic_questions = [\n",
    "    \"What are the main challenges in AI safety according to the research?\",\n",
    "    \"Explain the innovations in transformer architectures\",\n",
    "    \"What are the ethical concerns about AI development?\",\n",
    "    \"Summarize the research on language model optimization\",\n",
    "    \"What approaches are proposed for privacy in AI?\",\n",
    "    \"How is AI being used to address climate change?\",\n",
    "    \"What are the key insights about scaling laws in language models?\",\n",
    "]\n",
    "\n",
    "# SET 6: COMPLEX MULTI-HOP QUERIES (KG should excel)\n",
    "complex_questions = [\n",
    "    \"Which researchers work on the same topics as Emily Chen?\",\n",
    "    \"Find researchers who collaborate with colleagues of David Johnson\",\n",
    "    \"What topics connect Michael Brown and Sarah Lee?\",\n",
    "    \"Which researchers published in both 2023 and 2024?\",\n",
    "    \"Find articles that bridge multiple subtopics\",\n",
    "    \"Who are the most connected researchers in the collaboration network?\",\n",
    "]\n",
    "\n",
    "# SET 7: TEMPORAL QUERIES (KG should win)\n",
    "temporal_questions = [\n",
    "    \"What research was published in the last quarter of 2023?\",\n",
    "    \"Which topics were most popular in 2024?\",\n",
    "    \"Show the research timeline for Emily Chen\",\n",
    "    \"What was the first paper published on AI Ethics?\",\n",
    "    \"Compare publication activity between 2023 and 2024\",\n",
    "]\n",
    "\n",
    "# SET 8: COMPARISON QUERIES (Mixed)\n",
    "comparison_questions = [\n",
    "    \"Compare the research focus of Emily Chen vs Michael Brown\",\n",
    "    \"Which topic has more researchers: AI Ethics or Language Models?\",\n",
    "    \"Who is more prolific: David Johnson or Sarah Lee?\",\n",
    "    \"Compare collaboration patterns between different research areas\",\n",
    "]\n",
    "\n",
    "# ============================================\n",
    "# COMPREHENSIVE EVALUATION SUITE\n",
    "# ============================================\n",
    "\n",
    "def run_comprehensive_evaluation():\n",
    "    \"\"\"Run evaluation across all question types\"\"\"\n",
    "\n",
    "    evaluation_sets = {\n",
    "        \"Relationship Queries (KG Expected to Win)\": relationship_questions,\n",
    "        \"Counting & Aggregation (KG Expected to Win)\": counting_questions,\n",
    "        \"Filtering Queries (KG Expected to Win)\": filtering_questions,\n",
    "        \"Topic Queries (Mixed Results)\": topic_questions,\n",
    "        \"Semantic/Content Queries (RAG Expected to Win)\": semantic_questions,\n",
    "        \"Complex Multi-hop (KG Expected to Win)\": complex_questions,\n",
    "        \"Temporal Queries (KG Expected to Win)\": temporal_questions,\n",
    "        \"Comparison Queries (Mixed)\": comparison_questions,\n",
    "    }\n",
    "\n",
    "    print(\"\\n\" + \"\ud83c\udfaf\" * 40)\n",
    "    print(\"COMPREHENSIVE EVALUATION SUITE\")\n",
    "    print(\"\ud83c\udfaf\" * 40)\n",
    "    print(f\"\\nTotal Question Sets: {len(evaluation_sets)}\")\n",
    "    print(f\"Total Questions: {sum(len(qs) for qs in evaluation_sets.values())}\")\n",
    "\n",
    "    all_results = {}\n",
    "\n",
    "    for set_name, questions in evaluation_sets.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"\ud83d\udccb {set_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Questions: {len(questions)}\")\n",
    "\n",
    "        results = batch_judge_questions(questions)\n",
    "        all_results[set_name] = results\n",
    "\n",
    "        # Quick summary for this set\n",
    "        rag_wins = sum(1 for r in results if r.get('winner') == 'A')\n",
    "        kg_wins = sum(1 for r in results if r.get('winner') == 'B')\n",
    "        ties = sum(1 for r in results if r.get('winner') == 'TIE')\n",
    "\n",
    "        print(f\"\\n\ud83d\udcca Set Results:\")\n",
    "        print(f\"  RAG: {rag_wins}, KG: {kg_wins}, Ties: {ties}\")\n",
    "\n",
    "    # Overall statistics\n",
    "    print(\"\\n\" + \"\ud83c\udfc6\" * 40)\n",
    "    print(\"OVERALL EVALUATION RESULTS\")\n",
    "    print(\"\ud83c\udfc6\" * 40)\n",
    "\n",
    "    total_rag_wins = sum(\n",
    "        sum(1 for r in results if r.get('winner') == 'A')\n",
    "        for results in all_results.values()\n",
    "    )\n",
    "    total_kg_wins = sum(\n",
    "        sum(1 for r in results if r.get('winner') == 'B')\n",
    "        for results in all_results.values()\n",
    "    )\n",
    "    total_ties = sum(\n",
    "        sum(1 for r in results if r.get('winner') == 'TIE')\n",
    "        for results in all_results.values()\n",
    "    )\n",
    "    total_questions = total_rag_wins + total_kg_wins + total_ties\n",
    "\n",
    "    print(f\"\\n\ud83d\udcc8 Aggregate Statistics:\")\n",
    "    print(f\"  Total Questions: {total_questions}\")\n",
    "    print(f\"  RAG Wins: {total_rag_wins} ({total_rag_wins/total_questions*100:.1f}%)\")\n",
    "    print(f\"  KG Wins: {total_kg_wins} ({total_kg_wins/total_questions*100:.1f}%)\")\n",
    "    print(f\"  Ties: {total_ties} ({total_ties/total_questions*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\n\ud83c\udfaf Performance by Question Type:\")\n",
    "    for set_name, results in all_results.items():\n",
    "        rag = sum(1 for r in results if r.get('winner') == 'A')\n",
    "        kg = sum(1 for r in results if r.get('winner') == 'B')\n",
    "        tie = sum(1 for r in results if r.get('winner') == 'TIE')\n",
    "        total = len(results)\n",
    "\n",
    "        winner = \"RAG\" if rag > kg else \"KG\" if kg > rag else \"TIE\"\n",
    "        print(f\"\\n  {set_name}\")\n",
    "        print(f\"    Winner: {winner}\")\n",
    "        print(f\"    RAG: {rag}/{total} ({rag/total*100:.0f}%), KG: {kg}/{total} ({kg/total*100:.0f}%), Ties: {tie}/{total}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# QUICK EVALUATION SETS\n",
    "# ============================================\n",
    "\n",
    "# Small set for quick testing (10 questions)\n",
    "quick_eval_questions = [\n",
    "    # Relationship (KG should win)\n",
    "    \"Who are the collaborators of Emily Chen?\",\n",
    "\n",
    "    # Counting (KG should win)\n",
    "    \"How many articles has each researcher published?\",\n",
    "\n",
    "    # Filtering (KG should win)\n",
    "    \"Show me all articles published by David Johnson\",\n",
    "\n",
    "    # Topic (Mixed)\n",
    "    \"Which researchers work on AI Ethics?\",\n",
    "\n",
    "    # Semantic (RAG should win)\n",
    "    \"What are the main challenges in AI safety?\",\n",
    "\n",
    "    # Complex (KG should win)\n",
    "    \"Which researchers work on the same topics as Emily Chen?\",\n",
    "\n",
    "    # Temporal (KG should win)\n",
    "    \"What research was published in 2024?\",\n",
    "\n",
    "    # Comparison (Mixed)\n",
    "    \"Compare the research focus of Emily Chen vs Michael Brown\",\n",
    "\n",
    "    # Counting (KG should win)\n",
    "    \"Which topic has the most publications?\",\n",
    "\n",
    "    # Semantic (RAG should win)\n",
    "    \"Explain the innovations in transformer architectures\",\n",
    "]\n",
    "\n",
    "# Medium set for balanced testing (20 questions)\n",
    "medium_eval_questions = relationship_questions + counting_questions[:3] + topic_questions[:3] + semantic_questions[:3] + complex_questions[:3] + temporal_questions[:3]\n",
    "\n",
    "# Curated set highlighting strengths/weaknesses\n",
    "strength_weakness_questions = [\n",
    "    # KG Strengths\n",
    "    \"Who collaborated with whom on Model Optimization papers?\",\n",
    "    \"How many co-authors does each researcher have?\",\n",
    "    \"Find all papers published between June and December 2023\",\n",
    "    \"Which researchers published exactly 2 papers?\",\n",
    "\n",
    "    # RAG Strengths\n",
    "    \"What are the key innovations proposed for transformer architectures?\",\n",
    "    \"Summarize the ethical concerns discussed in AI research\",\n",
    "    \"Explain the privacy-preserving techniques mentioned in the papers\",\n",
    "    \"What solutions are proposed for AI bias mitigation?\",\n",
    "\n",
    "    # Edge Cases (where both might struggle)\n",
    "    \"What is the citation impact of each paper?\",  # Data not in graph\n",
    "    \"Compare the technical depth of papers on Safety\",  # Subjective\n",
    "    \"Predict future research directions based on current trends\",  # Speculative\n",
    "    \"Which paper had the most innovative methodology?\",  # Requires judgment\n",
    "]\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# USAGE EXAMPLES\n",
    "# ============================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Option 1: Quick evaluation (10 questions)\n",
    "    print(\"Running quick evaluation...\")\n",
    "    batch_judge_questions(quick_eval_questions)\n",
    "\n",
    "    # Option 2: Medium evaluation (20 questions)\n",
    "    # print(\"Running medium evaluation...\")\n",
    "    # batch_judge_questions(medium_eval_questions)\n",
    "\n",
    "    # Option 3: Comprehensive evaluation (all sets)\n",
    "    # print(\"Running comprehensive evaluation...\")\n",
    "    # run_comprehensive_evaluation()\n",
    "\n",
    "    # Option 4: Strength/Weakness analysis\n",
    "    # print(\"Running strength/weakness analysis...\")\n",
    "    # batch_judge_questions(strength_weakness_questions)\n",
    "\n",
    "    # Option 5: Focus on specific question type\n",
    "    # print(\"Evaluating relationship queries...\")\n",
    "    # batch_judge_questions(relationship_questions)"
   ],
   "metadata": {
    "id": "bc3yzQuWY5rT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## \ud83d\ude80 **Ready to Build Production-Ready AI Systems?**\n\nYou've just seen a comprehensive comparison of RAG and Knowledge Graph approaches. But this is just the beginning!\n\n### **Take Your Skills to the Next Level**\n\nJoin the **Advanced LLM Multi-Agent Architecture Course** and learn:\n\n- \ud83c\udfaf **Multi-Agent Orchestration** - Design and implement complex agent systems\n- \ud83d\udd04 **Hybrid Architectures** - Combine RAG, Knowledge Graphs, and more\n- \ud83d\udcca **Evaluation & Monitoring** - Build robust evaluation frameworks\n- \ud83c\udfd7\ufe0f **Production Deployment** - Scale your AI systems effectively\n- \ud83d\udca1 **Real-World Projects** - Work on enterprise-grade case studies\n\n### **Special Offer for Learners**\n\n**[\ud83c\udf93 Enroll Now](https://maven.com/boring-bot/advanced-llm?promoCode=200OFF)** and use code **`200OFF`** to save $200!\n\n---\n\n### **What You'll Gain:**\n\n\u2705 Deep understanding of multi-agent architectures  \n\u2705 Hands-on experience with production patterns  \n\u2705 Expert guidance from industry practitioners  \n\u2705 A portfolio of real-world AI projects  \n\u2705 Community access for ongoing support  \n\n**[Start Building Advanced AI Systems Today \u2192](https://maven.com/boring-bot/advanced-llm?promoCode=200OFF)**\n\n---\n\n*Built with \u2764\ufe0f for the AI community. Questions? Reach out to the course instructors!*",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "# **\ud83d\udcca Summary Table: Expected Winners by Question Type**\n",
    "\n",
    "| **Question Category**             | **Description**                                              | **Expected Winner**  |\n",
    "| --------------------------------- | ------------------------------------------------------------ | -------------------- |\n",
    "| **1. Relationship Queries**       | Entity\u2013entity links, co-authorship, collaboration paths      | **KG**               |\n",
    "| **2. Counting & Aggregation**     | Counts, totals, group-by operations                          | **KG**               |\n",
    "| **3. Filtering Queries**          | Direct filters: by researcher, year, topic                   | **KG**               |\n",
    "| **4. Topic-Based Queries**        | Topic membership, topic hierarchy, thematic grouping         | **Mixed (KG + RAG)** |\n",
    "| **5. Semantic / Content Queries** | Summaries, insights, conceptual explanations                 | **RAG**              |\n",
    "| **6. Complex Multi-Hop Queries**  | Multi-step graph reasoning, indirect relationships           | **KG**               |\n",
    "| **7. Temporal Queries**           | Timelines, date filtering, year-based comparisons            | **KG**               |\n",
    "| **8. Comparison Queries**         | Entity-to-entity comparisons (focus, productivity, networks) | **Mixed**            |\n",
    "\n",
    "---\n",
    "\n",
    "# **\ud83c\udfc6 Winner Overview**\n",
    "\n",
    "| **Method**               | **Types of Questions It Excels At**                                          |\n",
    "| ------------------------ | ---------------------------------------------------------------------------- |\n",
    "| **Knowledge Graph (KG)** | Relationship, counting, strict filtering, multi-hop, temporal logic          |\n",
    "| **RAG**                  | Semantic interpretation, explanations, summaries, contextual reasoning       |\n",
    "| **Mixed**                | Topic-based questions, comparisons requiring both structure + interpretation |\n",
    "\n"
   ],
   "metadata": {
    "id": "3lvQpIWpa-cd"
   }
  }
 ]
}